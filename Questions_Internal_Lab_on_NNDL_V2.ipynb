{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions - Internal Lab on NNDL_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeoiMbH7djEv"
      },
      "source": [
        "# Stock prices dataset\n",
        "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
        "\n",
        "## Description\n",
        "A brief description of columns.\n",
        "- open: The opening market price of the equity symbol on the date\n",
        "- high: The highest market price of the equity symbol on the date\n",
        "- low: The lowest recorded market price of the equity symbol on the date\n",
        "- close: The closing recorded price of the equity symbol on the date\n",
        "- symbol: Symbol of the listed company\n",
        "- volume: Total traded volume of the equity symbol on the date\n",
        "- date: Date of record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSoYY2nII_UW"
      },
      "source": [
        "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGqq9f8VdLba"
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_88voqAH-O6J"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRHCeJqP-evf"
      },
      "source": [
        "### Load the data\n",
        "- load the csv file and read it using pandas\n",
        "- file name is prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKVH5v7r-RmC"
      },
      "source": [
        "# run this cell to upload file using GUI if you are using google colab\n",
        "\n",
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4YcffYd1FQ"
      },
      "source": [
        "# run this cell to to mount the google drive if you are using google colab\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/My Drive/')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hr4t6D7BfUX"
      },
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFxTaNy3IAXO"
      },
      "source": [
        "# Importing the dataset \n",
        "df = pd.read_csv('prices.csv')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCo5-59ymPev",
        "outputId": "bcf5bc45-0f48-434c-9b80-484a74a01574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlLKVPVH_BCT"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxoGynuBeO4t"
      },
      "source": [
        "### Drop null\n",
        "- Drop null values if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9legFNJxn6JR",
        "outputId": "c782eeb9-927f-4ef3-80a4-d3469100361a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date      0\n",
              "symbol    0\n",
              "open      0\n",
              "close     0\n",
              "low       0\n",
              "high      0\n",
              "volume    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yuwJJIeeUaD",
        "outputId": "bbbde3b3-baf5-4f9d-9b9e-c4dc7877bc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#There are no null values in this dataset as nan\n",
        "df.info()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 851264 entries, 0 to 851263\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   date    851264 non-null  object \n",
            " 1   symbol  851264 non-null  object \n",
            " 2   open    851264 non-null  float64\n",
            " 3   close   851264 non-null  float64\n",
            " 4   low     851264 non-null  float64\n",
            " 5   high    851264 non-null  float64\n",
            " 6   volume  851264 non-null  float64\n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 45.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4BlzVA_gZd"
      },
      "source": [
        "### Drop columns\n",
        "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
        "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi__FzdLnFWh"
      },
      "source": [
        "# Creating a copy before deleting the columns\n",
        "\n",
        "df_copy = df.copy()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKEK8aEE_Csx"
      },
      "source": [
        "df.drop(columns = ['date','volume','symbol'], axis=1, inplace=True )"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5w3uGfSnQ3E",
        "outputId": "f62ddfc7-45d5-439d-c3e9-07d1a8949ff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 851264 entries, 0 to 851263\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   open    851264 non-null  float64\n",
            " 1   close   851264 non-null  float64\n",
            " 2   low     851264 non-null  float64\n",
            " 3   high    851264 non-null  float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 26.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTPhO6v-AiZt"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsZXmF3NAkna"
      },
      "source": [
        "### Print the dataframe\n",
        "- print the modified dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKs04iIHAjxN",
        "outputId": "ff6de23b-59ae-41c8-b3c9-e3dca1e0e30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851259</th>\n",
              "      <td>103.309998</td>\n",
              "      <td>103.199997</td>\n",
              "      <td>102.849998</td>\n",
              "      <td>103.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851260</th>\n",
              "      <td>43.070000</td>\n",
              "      <td>43.040001</td>\n",
              "      <td>42.689999</td>\n",
              "      <td>43.310001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851261</th>\n",
              "      <td>53.639999</td>\n",
              "      <td>53.529999</td>\n",
              "      <td>53.270000</td>\n",
              "      <td>53.740002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851262</th>\n",
              "      <td>44.730000</td>\n",
              "      <td>45.450001</td>\n",
              "      <td>44.410000</td>\n",
              "      <td>45.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851263</th>\n",
              "      <td>54.200001</td>\n",
              "      <td>53.630001</td>\n",
              "      <td>53.389999</td>\n",
              "      <td>54.480000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>851264 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              open       close         low        high\n",
              "0       123.430000  125.839996  122.309998  126.250000\n",
              "1       125.239998  119.980003  119.940002  125.540001\n",
              "2       116.379997  114.949997  114.930000  119.739998\n",
              "3       115.480003  116.620003  113.500000  117.440002\n",
              "4       117.010002  114.970001  114.089996  117.330002\n",
              "...            ...         ...         ...         ...\n",
              "851259  103.309998  103.199997  102.849998  103.930000\n",
              "851260   43.070000   43.040001   42.689999   43.310001\n",
              "851261   53.639999   53.529999   53.270000   53.740002\n",
              "851262   44.730000   45.450001   44.410000   45.590000\n",
              "851263   54.200001   53.630001   53.389999   54.480000\n",
              "\n",
              "[851264 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8u_jlbABTip"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
        "- Take \"open\" \"low\", \"high\" columns as features\n",
        "- Take \"close\" column as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nph2yDo3pEBF"
      },
      "source": [
        "# X are features and y are labels\n",
        "X = df.drop('close', axis=1)\n",
        "y = df['close']"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQjCMzUXBJbg",
        "outputId": "499553d9-b7b3-46a7-ffeb-e2be47869530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X.head())\n",
        "y.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         open         low        high\n",
            "0  123.430000  122.309998  126.250000\n",
            "1  125.239998  119.940002  125.540001\n",
            "2  116.379997  114.930000  119.739998\n",
            "3  115.480003  113.500000  117.440002\n",
            "4  117.010002  114.089996  117.330002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    125.839996\n",
              "1    119.980003\n",
              "2    114.949997\n",
              "3    116.620003\n",
              "4    114.970001\n",
              "Name: close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGtnapgBIJm"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZAKdJ5gcrm"
      },
      "source": [
        "### Create train and test sets\n",
        "- Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KalRqA6Rgqsn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.3, random_state=100)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAKzlxZBz0z"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7BU2qxEg0Ki"
      },
      "source": [
        "### Scaling\n",
        "- Scale the data (features only)\n",
        "- Use StandarScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcO8SlhPhBkR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_X = scaler.fit_transform(train_X)\n",
        "test_X = scaler.transform(test_X) "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93H7TVx6ssPa",
        "outputId": "afea0ad4-bf08-4e17-8d53-d17b508ad5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_X)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.18083958 -0.18336376 -0.18579603]\n",
            " [-0.59051571 -0.59102358 -0.59231908]\n",
            " [-0.31256824 -0.30828594 -0.31133643]\n",
            " ...\n",
            " [-0.63698001 -0.6350426  -0.6370532 ]\n",
            " [-0.37424123 -0.37757963 -0.37742906]\n",
            " [-0.59650337 -0.59598176 -0.59754002]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TWpN0nVTpUx"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sj0LYNkhR-L"
      },
      "source": [
        "### Convert data to NumPy array\n",
        "- Convert features and labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mIfuTxhbTT",
        "outputId": "3be39499-948f-497b-e453-d9afe0787db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(type(train_X))\n",
        "print(type(train_y))\n",
        "print(type(test_X))\n",
        "print(type(test_y))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xinsAHolvAtu"
      },
      "source": [
        "train_y = train_y.to_numpy()\n",
        "test_y = test_y.to_numpy()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niTmCupivJAq",
        "outputId": "e93e4cdf-606d-46dd-9b97-96105b4168fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(train_X))\n",
        "print(type(train_y))\n",
        "print(type(test_X))\n",
        "print(type(test_y))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmXUGc2oTspa"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl2M9whFh6mh"
      },
      "source": [
        "### Define Model\n",
        "- Initialize a Sequential model\n",
        "- Add a Flatten layer\n",
        "- Add a Dense layer with one neuron as output\n",
        "  - add 'linear' as activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiBpORmiegL"
      },
      "source": [
        "#Clear any existing model in memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Input data\n",
        "#model.add(tf.keras.Input(shape = (3,)))\n",
        "\n",
        "#Flatten data\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Add a dense layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='linear'))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a0wr94aTyjg"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNZPb5lKioX0"
      },
      "source": [
        "### Compile the model\n",
        "- Compile the model\n",
        "- Use \"sgd\" optimizer\n",
        "- for calculating loss, use mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEQUP3VaiuT2"
      },
      "source": [
        "# Compiling model\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbBpnOtfT0wd"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9o45OHdjDhA"
      },
      "source": [
        "### Fit the model\n",
        "- epochs: 50\n",
        "- batch size: 128\n",
        "- specify validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y6tA30XjOH2",
        "outputId": "a6a9932c-4f44-40dc-d66a-f572c8dc2d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting model\n",
        "model.fit(x=train_X, y=train_y, batch_size=128, epochs=50, validation_data=(test_X, test_y))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 41.3348 - accuracy: 3.3564e-06 - val_loss: 0.9535 - val_accuracy: 3.9157e-06\n",
            "Epoch 2/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9683 - accuracy: 3.3564e-06 - val_loss: 0.9629 - val_accuracy: 3.9157e-06\n",
            "Epoch 3/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9618 - accuracy: 3.3564e-06 - val_loss: 0.9401 - val_accuracy: 3.9157e-06\n",
            "Epoch 4/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9546 - accuracy: 3.3564e-06 - val_loss: 0.9334 - val_accuracy: 3.9157e-06\n",
            "Epoch 5/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9488 - accuracy: 3.3564e-06 - val_loss: 0.9290 - val_accuracy: 3.9157e-06\n",
            "Epoch 6/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9404 - accuracy: 3.3564e-06 - val_loss: 0.9222 - val_accuracy: 3.9157e-06\n",
            "Epoch 7/50\n",
            "4656/4656 [==============================] - 6s 1ms/step - loss: 0.9342 - accuracy: 3.3564e-06 - val_loss: 0.9167 - val_accuracy: 3.9157e-06\n",
            "Epoch 8/50\n",
            "4656/4656 [==============================] - 5s 1ms/step - loss: 0.9284 - accuracy: 3.3564e-06 - val_loss: 0.9101 - val_accuracy: 3.9157e-06\n",
            "Epoch 9/50\n",
            "4656/4656 [==============================] - 4s 931us/step - loss: 0.9226 - accuracy: 3.3564e-06 - val_loss: 0.9078 - val_accuracy: 3.9157e-06\n",
            "Epoch 10/50\n",
            "4656/4656 [==============================] - 4s 933us/step - loss: 0.9150 - accuracy: 3.3564e-06 - val_loss: 0.8982 - val_accuracy: 3.9157e-06\n",
            "Epoch 11/50\n",
            "4656/4656 [==============================] - 4s 939us/step - loss: 0.9092 - accuracy: 3.3564e-06 - val_loss: 0.8919 - val_accuracy: 3.9157e-06\n",
            "Epoch 12/50\n",
            "4656/4656 [==============================] - 4s 933us/step - loss: 0.9013 - accuracy: 3.3564e-06 - val_loss: 0.9025 - val_accuracy: 3.9157e-06\n",
            "Epoch 13/50\n",
            "4656/4656 [==============================] - 4s 941us/step - loss: 0.8953 - accuracy: 3.3564e-06 - val_loss: 0.8807 - val_accuracy: 3.9157e-06\n",
            "Epoch 14/50\n",
            "4656/4656 [==============================] - 4s 940us/step - loss: 0.8899 - accuracy: 3.3564e-06 - val_loss: 0.9375 - val_accuracy: 3.9157e-06\n",
            "Epoch 15/50\n",
            "4656/4656 [==============================] - 4s 936us/step - loss: 0.8840 - accuracy: 3.3564e-06 - val_loss: 0.8836 - val_accuracy: 3.9157e-06\n",
            "Epoch 16/50\n",
            "4656/4656 [==============================] - 4s 947us/step - loss: 0.8774 - accuracy: 3.3564e-06 - val_loss: 0.8786 - val_accuracy: 3.9157e-06\n",
            "Epoch 17/50\n",
            "4656/4656 [==============================] - 4s 941us/step - loss: 0.8723 - accuracy: 3.3564e-06 - val_loss: 0.8563 - val_accuracy: 3.9157e-06\n",
            "Epoch 18/50\n",
            "4656/4656 [==============================] - 4s 930us/step - loss: 0.8675 - accuracy: 3.3564e-06 - val_loss: 0.8671 - val_accuracy: 3.9157e-06\n",
            "Epoch 19/50\n",
            "4656/4656 [==============================] - 4s 940us/step - loss: 0.8601 - accuracy: 3.3564e-06 - val_loss: 0.8859 - val_accuracy: 3.9157e-06\n",
            "Epoch 20/50\n",
            "4656/4656 [==============================] - 4s 940us/step - loss: 0.8539 - accuracy: 3.3564e-06 - val_loss: 0.8641 - val_accuracy: 3.9157e-06\n",
            "Epoch 21/50\n",
            "4656/4656 [==============================] - 4s 933us/step - loss: 0.8484 - accuracy: 3.3564e-06 - val_loss: 0.8382 - val_accuracy: 3.9157e-06\n",
            "Epoch 22/50\n",
            "4656/4656 [==============================] - 4s 944us/step - loss: 0.8428 - accuracy: 3.3564e-06 - val_loss: 0.8326 - val_accuracy: 3.9157e-06\n",
            "Epoch 23/50\n",
            "4656/4656 [==============================] - 4s 943us/step - loss: 0.8384 - accuracy: 3.3564e-06 - val_loss: 0.8254 - val_accuracy: 3.9157e-06\n",
            "Epoch 24/50\n",
            "4656/4656 [==============================] - 4s 944us/step - loss: 0.8332 - accuracy: 3.3564e-06 - val_loss: 0.8397 - val_accuracy: 3.9157e-06\n",
            "Epoch 25/50\n",
            "4656/4656 [==============================] - 4s 940us/step - loss: 0.8262 - accuracy: 3.3564e-06 - val_loss: 0.8151 - val_accuracy: 3.9157e-06\n",
            "Epoch 26/50\n",
            "4656/4656 [==============================] - 4s 950us/step - loss: 0.8236 - accuracy: 3.3564e-06 - val_loss: 0.8106 - val_accuracy: 3.9157e-06\n",
            "Epoch 27/50\n",
            "4656/4656 [==============================] - 4s 950us/step - loss: 0.8165 - accuracy: 3.3564e-06 - val_loss: 0.8180 - val_accuracy: 3.9157e-06\n",
            "Epoch 28/50\n",
            "4656/4656 [==============================] - 4s 935us/step - loss: 0.8123 - accuracy: 3.3564e-06 - val_loss: 0.8142 - val_accuracy: 3.9157e-06\n",
            "Epoch 29/50\n",
            "4656/4656 [==============================] - 4s 950us/step - loss: 0.8063 - accuracy: 3.3564e-06 - val_loss: 0.7967 - val_accuracy: 3.9157e-06\n",
            "Epoch 30/50\n",
            "4656/4656 [==============================] - 4s 935us/step - loss: 0.8017 - accuracy: 3.3564e-06 - val_loss: 0.7970 - val_accuracy: 3.9157e-06\n",
            "Epoch 31/50\n",
            "4656/4656 [==============================] - 4s 930us/step - loss: 0.7970 - accuracy: 3.3564e-06 - val_loss: 0.7866 - val_accuracy: 3.9157e-06\n",
            "Epoch 32/50\n",
            "4656/4656 [==============================] - 4s 949us/step - loss: 0.7931 - accuracy: 3.3564e-06 - val_loss: 0.7976 - val_accuracy: 3.9157e-06\n",
            "Epoch 33/50\n",
            "4656/4656 [==============================] - 4s 939us/step - loss: 0.7874 - accuracy: 3.3564e-06 - val_loss: 0.7885 - val_accuracy: 3.9157e-06\n",
            "Epoch 34/50\n",
            "4656/4656 [==============================] - 4s 951us/step - loss: 0.7810 - accuracy: 3.3564e-06 - val_loss: 0.8084 - val_accuracy: 3.9157e-06\n",
            "Epoch 35/50\n",
            "4656/4656 [==============================] - 4s 944us/step - loss: 0.7784 - accuracy: 3.3564e-06 - val_loss: 0.7740 - val_accuracy: 3.9157e-06\n",
            "Epoch 36/50\n",
            "4656/4656 [==============================] - 4s 933us/step - loss: 0.7733 - accuracy: 3.3564e-06 - val_loss: 0.7646 - val_accuracy: 3.9157e-06\n",
            "Epoch 37/50\n",
            "4656/4656 [==============================] - 4s 937us/step - loss: 0.7700 - accuracy: 3.3564e-06 - val_loss: 0.7680 - val_accuracy: 3.9157e-06\n",
            "Epoch 38/50\n",
            "4656/4656 [==============================] - 4s 935us/step - loss: 0.7647 - accuracy: 3.3564e-06 - val_loss: 0.7702 - val_accuracy: 3.9157e-06\n",
            "Epoch 39/50\n",
            "4656/4656 [==============================] - 4s 951us/step - loss: 0.7597 - accuracy: 3.3564e-06 - val_loss: 0.7526 - val_accuracy: 3.9157e-06\n",
            "Epoch 40/50\n",
            "4656/4656 [==============================] - 4s 943us/step - loss: 0.7554 - accuracy: 3.3564e-06 - val_loss: 0.7503 - val_accuracy: 3.9157e-06\n",
            "Epoch 41/50\n",
            "4656/4656 [==============================] - 4s 938us/step - loss: 0.7520 - accuracy: 3.3564e-06 - val_loss: 0.7445 - val_accuracy: 3.9157e-06\n",
            "Epoch 42/50\n",
            "4656/4656 [==============================] - 4s 943us/step - loss: 0.7474 - accuracy: 3.3564e-06 - val_loss: 0.7410 - val_accuracy: 3.9157e-06\n",
            "Epoch 43/50\n",
            "4656/4656 [==============================] - 4s 937us/step - loss: 0.7436 - accuracy: 3.3564e-06 - val_loss: 0.7735 - val_accuracy: 3.9157e-06\n",
            "Epoch 44/50\n",
            "4656/4656 [==============================] - 4s 948us/step - loss: 0.7376 - accuracy: 3.3564e-06 - val_loss: 0.7336 - val_accuracy: 3.9157e-06\n",
            "Epoch 45/50\n",
            "4656/4656 [==============================] - 4s 943us/step - loss: 0.7349 - accuracy: 3.3564e-06 - val_loss: 0.7286 - val_accuracy: 3.9157e-06\n",
            "Epoch 46/50\n",
            "4656/4656 [==============================] - 4s 950us/step - loss: 0.7297 - accuracy: 3.3564e-06 - val_loss: 0.7250 - val_accuracy: 3.9157e-06\n",
            "Epoch 47/50\n",
            "4656/4656 [==============================] - 4s 949us/step - loss: 0.7264 - accuracy: 3.3564e-06 - val_loss: 0.7475 - val_accuracy: 3.9157e-06\n",
            "Epoch 48/50\n",
            "4656/4656 [==============================] - 4s 940us/step - loss: 0.7226 - accuracy: 3.3564e-06 - val_loss: 0.7328 - val_accuracy: 3.9157e-06\n",
            "Epoch 49/50\n",
            "4656/4656 [==============================] - 4s 945us/step - loss: 0.7182 - accuracy: 3.3564e-06 - val_loss: 0.7336 - val_accuracy: 3.9157e-06\n",
            "Epoch 50/50\n",
            "4656/4656 [==============================] - 4s 956us/step - loss: 0.7143 - accuracy: 3.3564e-06 - val_loss: 0.7164 - val_accuracy: 3.9157e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbdabc6ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW4SEP8kT2ls"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJDoix_7JU61"
      },
      "source": [
        "### Evaluate the model\n",
        "- Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdH8pYBIjHGL",
        "outputId": "a7532ff7-bc34-4488-8b2b-5860289f4d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_X,test_y)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7981/7981 [==============================] - 8s 971us/step - loss: 0.7164 - accuracy: 3.9157e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7163580656051636, 3.9157334867923055e-06]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUpDD74Xjh01"
      },
      "source": [
        "### Manual predictions\n",
        "- Test the predictions on manual inputs\n",
        "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler\n",
        "- Example of manual input: [123.430000,\t122.30999, 116.250000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvuH-c31lLiJ",
        "outputId": "b3d0f384-540f-4c80-d99c-6551dfbbb26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_data = np.expand_dims([123.430000, 122.30999, 116.250000], axis=0)\n",
        "prediction = model.predict(scaler.transform(input_data))\n",
        "prediction"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[119.72916]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsjb2I1VDBkW"
      },
      "source": [
        "For the scope of this assignment, we have considered a very elemental form of a neural network where we have taken a single neuron with a single layer and a linear activation function. Hence, the accuracy isn't very high. Higher accuracy can be achieved as hyper parameters are tuned and more nuerons and layers added. With a single layer and a neuron, it could only learn so much in a regression setting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WH1Pr4KQlCh"
      },
      "source": [
        "# Build a DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cQBsi5QlCw"
      },
      "source": [
        "### Collect Fashion mnist data from tf.keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWy0oDTr2Kj",
        "outputId": "6b73e098-a52a-4f8c-ab62-7129cac9e59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(trainX,trainY),(testX,testY) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9quhxY7JKZ7e",
        "outputId": "55589660-b798-46f0-d8c3-8b1331cc2a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtEdeJIlL1oq",
        "outputId": "b08d8456-c152-42be-c53b-d653b85f05d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Unique classes in our dataset\n",
        "set(trainY)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69C3bEvLMu_L",
        "outputId": "f46ed1bb-83dd-44df-9264-6262b7e5441b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#sample image\n",
        "plt.imshow(trainX[1],cmap='gray')\n",
        "plt.show() "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7aWYZyQlC1"
      },
      "source": [
        "### Change train and test labels into one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6otc4wQlC2"
      },
      "source": [
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuyXwI9wPd0P",
        "outputId": "017f4dd4-5e07-4d09-dda4-c65685b88418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(testY.shape)\n",
        "trainY.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjNrRTdoQlC5"
      },
      "source": [
        "### Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDJ9DHVNQlC7"
      },
      "source": [
        "### Initialize model, reshape & normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDQs_g1QlC8"
      },
      "source": [
        "# reshape the data\n",
        "trainX = trainX.reshape(trainX.shape[0], 28, 28, 1)\n",
        "testX = testX.reshape(testX.shape[0], 28, 28, 1) \n",
        "# Normalizing the Data\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "\n",
        "trainX /= 255\n",
        "testX /= 255 "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSi4UObjUGSP"
      },
      "source": [
        "#Clear any existing model in memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBGwTTilQlDD"
      },
      "source": [
        "### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbfpfOzQlDF"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "model.add(Dropout(0.25)) "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I8f5otcQlDJ"
      },
      "source": [
        "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZkvKymSd0Sr"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "# Compiling model\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\"], \n",
        "              optimizer=\"adam\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR3guOScIAYG",
        "outputId": "556085de-f479-4bbf-dc61-1ea6aaf7500f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting model\n",
        "model.fit(x=trainX, y=trainY, batch_size=20, epochs=60, validation_data=(testX, testY))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.5443 - accuracy: 0.8105 - val_loss: 0.4603 - val_accuracy: 0.8407\n",
            "Epoch 2/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.4234 - accuracy: 0.8484 - val_loss: 0.4145 - val_accuracy: 0.8486\n",
            "Epoch 3/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3774 - accuracy: 0.8641 - val_loss: 0.3579 - val_accuracy: 0.8716\n",
            "Epoch 4/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3511 - accuracy: 0.8740 - val_loss: 0.3848 - val_accuracy: 0.8641\n",
            "Epoch 5/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3323 - accuracy: 0.8799 - val_loss: 0.3723 - val_accuracy: 0.8667\n",
            "Epoch 6/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3168 - accuracy: 0.8852 - val_loss: 0.3414 - val_accuracy: 0.8781\n",
            "Epoch 7/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.3069 - accuracy: 0.8886 - val_loss: 0.3623 - val_accuracy: 0.8737\n",
            "Epoch 8/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2950 - accuracy: 0.8925 - val_loss: 0.3440 - val_accuracy: 0.8744\n",
            "Epoch 9/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2844 - accuracy: 0.8967 - val_loss: 0.3401 - val_accuracy: 0.8803\n",
            "Epoch 10/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2771 - accuracy: 0.8990 - val_loss: 0.3323 - val_accuracy: 0.8792\n",
            "Epoch 11/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2677 - accuracy: 0.9012 - val_loss: 0.3338 - val_accuracy: 0.8830\n",
            "Epoch 12/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2606 - accuracy: 0.9048 - val_loss: 0.3244 - val_accuracy: 0.8845\n",
            "Epoch 13/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2537 - accuracy: 0.9065 - val_loss: 0.3384 - val_accuracy: 0.8831\n",
            "Epoch 14/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2481 - accuracy: 0.9085 - val_loss: 0.3746 - val_accuracy: 0.8679\n",
            "Epoch 15/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.2401 - accuracy: 0.9110 - val_loss: 0.3276 - val_accuracy: 0.8854\n",
            "Epoch 16/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2368 - accuracy: 0.9131 - val_loss: 0.3277 - val_accuracy: 0.8886\n",
            "Epoch 17/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2302 - accuracy: 0.9157 - val_loss: 0.3340 - val_accuracy: 0.8840\n",
            "Epoch 18/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2244 - accuracy: 0.9177 - val_loss: 0.3344 - val_accuracy: 0.8868\n",
            "Epoch 19/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2195 - accuracy: 0.9196 - val_loss: 0.3274 - val_accuracy: 0.8855\n",
            "Epoch 20/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2164 - accuracy: 0.9190 - val_loss: 0.3562 - val_accuracy: 0.8800\n",
            "Epoch 21/60\n",
            "3000/3000 [==============================] - 9s 3ms/step - loss: 0.2136 - accuracy: 0.9212 - val_loss: 0.3377 - val_accuracy: 0.8930\n",
            "Epoch 22/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2082 - accuracy: 0.9213 - val_loss: 0.3527 - val_accuracy: 0.8841\n",
            "Epoch 23/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.2035 - accuracy: 0.9244 - val_loss: 0.3201 - val_accuracy: 0.8910\n",
            "Epoch 24/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1997 - accuracy: 0.9257 - val_loss: 0.3382 - val_accuracy: 0.8919\n",
            "Epoch 25/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1946 - accuracy: 0.9289 - val_loss: 0.3520 - val_accuracy: 0.8900\n",
            "Epoch 26/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1912 - accuracy: 0.9293 - val_loss: 0.3380 - val_accuracy: 0.8903\n",
            "Epoch 27/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 0.3399 - val_accuracy: 0.8868\n",
            "Epoch 28/60\n",
            "3000/3000 [==============================] - 9s 3ms/step - loss: 0.1856 - accuracy: 0.9309 - val_loss: 0.3500 - val_accuracy: 0.8870\n",
            "Epoch 29/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1824 - accuracy: 0.9321 - val_loss: 0.3383 - val_accuracy: 0.8947\n",
            "Epoch 30/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1782 - accuracy: 0.9345 - val_loss: 0.3652 - val_accuracy: 0.8902\n",
            "Epoch 31/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1744 - accuracy: 0.9356 - val_loss: 0.3537 - val_accuracy: 0.8938\n",
            "Epoch 32/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1739 - accuracy: 0.9362 - val_loss: 0.3758 - val_accuracy: 0.8891\n",
            "Epoch 33/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1696 - accuracy: 0.9381 - val_loss: 0.3674 - val_accuracy: 0.8917\n",
            "Epoch 34/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1698 - accuracy: 0.9366 - val_loss: 0.3505 - val_accuracy: 0.8925\n",
            "Epoch 35/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1648 - accuracy: 0.9386 - val_loss: 0.3610 - val_accuracy: 0.8949\n",
            "Epoch 36/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1634 - accuracy: 0.9388 - val_loss: 0.3703 - val_accuracy: 0.8901\n",
            "Epoch 37/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1591 - accuracy: 0.9405 - val_loss: 0.3558 - val_accuracy: 0.8930\n",
            "Epoch 38/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1576 - accuracy: 0.9419 - val_loss: 0.3726 - val_accuracy: 0.8939\n",
            "Epoch 39/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1592 - accuracy: 0.9413 - val_loss: 0.3540 - val_accuracy: 0.8949\n",
            "Epoch 40/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1538 - accuracy: 0.9433 - val_loss: 0.3995 - val_accuracy: 0.8855\n",
            "Epoch 41/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1524 - accuracy: 0.9428 - val_loss: 0.3766 - val_accuracy: 0.8940\n",
            "Epoch 42/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1495 - accuracy: 0.9458 - val_loss: 0.3656 - val_accuracy: 0.8919\n",
            "Epoch 43/60\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.1465 - accuracy: 0.9461 - val_loss: 0.3602 - val_accuracy: 0.8914\n",
            "Epoch 44/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1456 - accuracy: 0.9459 - val_loss: 0.3857 - val_accuracy: 0.8940\n",
            "Epoch 45/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1437 - accuracy: 0.9473 - val_loss: 0.3896 - val_accuracy: 0.8955\n",
            "Epoch 46/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1398 - accuracy: 0.9482 - val_loss: 0.4003 - val_accuracy: 0.8952\n",
            "Epoch 47/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1393 - accuracy: 0.9491 - val_loss: 0.4417 - val_accuracy: 0.8826\n",
            "Epoch 48/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1386 - accuracy: 0.9493 - val_loss: 0.4253 - val_accuracy: 0.8888\n",
            "Epoch 49/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1340 - accuracy: 0.9498 - val_loss: 0.3953 - val_accuracy: 0.8925\n",
            "Epoch 50/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1341 - accuracy: 0.9500 - val_loss: 0.3833 - val_accuracy: 0.8920\n",
            "Epoch 51/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1319 - accuracy: 0.9506 - val_loss: 0.4343 - val_accuracy: 0.8840\n",
            "Epoch 52/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1331 - accuracy: 0.9510 - val_loss: 0.4178 - val_accuracy: 0.8942\n",
            "Epoch 53/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1291 - accuracy: 0.9522 - val_loss: 0.4210 - val_accuracy: 0.8932\n",
            "Epoch 54/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1289 - accuracy: 0.9519 - val_loss: 0.3865 - val_accuracy: 0.8962\n",
            "Epoch 55/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1261 - accuracy: 0.9535 - val_loss: 0.4096 - val_accuracy: 0.8928\n",
            "Epoch 56/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1266 - accuracy: 0.9534 - val_loss: 0.4052 - val_accuracy: 0.8921\n",
            "Epoch 57/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1226 - accuracy: 0.9546 - val_loss: 0.4121 - val_accuracy: 0.8952\n",
            "Epoch 58/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1218 - accuracy: 0.9549 - val_loss: 0.4130 - val_accuracy: 0.8926\n",
            "Epoch 59/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1203 - accuracy: 0.9548 - val_loss: 0.4034 - val_accuracy: 0.8890\n",
            "Epoch 60/60\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.1187 - accuracy: 0.9553 - val_loss: 0.4373 - val_accuracy: 0.8924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbda7bf8710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSiMhJPpk3GO",
        "outputId": "e6303a50-91dc-4126-9517-6516f0105961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 178,510\n",
            "Trainable params: 178,310\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ZGn8pYWnot"
      },
      "source": [
        "We get a decent validation accuracy of 89%. Hyper parameters could be further tuned to get better results. "
      ]
    }
  ]
}